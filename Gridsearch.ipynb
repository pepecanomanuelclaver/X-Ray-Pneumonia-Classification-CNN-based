{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "18e9df60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# basics\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import zipfile\n",
    "import os\n",
    "import keras\n",
    "import tensorflow as tf\n",
    "\n",
    "#Models and layers\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten, Dropout\n",
    "from keras.applications.vgg16 import VGG16\n",
    "#optimizers TO be extended\n",
    "from keras.optimizers import Adam, RMSprop, SGD\n",
    "\n",
    "#stopping\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "#visualizing\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, classification_report,ConfusionMatrixDisplay\n",
    "from keras_preprocessing.image import img_to_array, array_to_img, load_img, ImageDataGenerator\n",
    "#gridsearch\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from keras.utils.np_utils import to_categorical\n",
    "\n",
    "import talos\n",
    "from talos.utils import lr_normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0dc142eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ziploc= \"E:/School/UU/PATREC/CXR_project/NEW_DATA/\"\n",
    "augmented_image_loc = \"E:/School/UU/PATREC/PR_images/\"\n",
    "og_image_loc = \"E:/School/UU/PATREC/.darwin/datasets/v7-labs/covid-19-chest-x-ray-dataset/images/\"\n",
    "store_model_loc = \"E:/School/UU/PATREC/checkpoints/\"\n",
    "\n",
    "all_img_loc = \"E:/School/UU/PATREC/PR_images/ALL/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf9c2978",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainzip =  zipfile.ZipFile(ziploc+'final_train_data.zip') \n",
    "train_df = pd.read_csv(trainzip.open('train_final.csv'))\n",
    "valzip =  zipfile.ZipFile(ziploc+'final_val_data.zip') \n",
    "val_df = pd.read_csv(valzip.open('val_final.csv'))\n",
    "testzip =  zipfile.ZipFile(ziploc+'final_test_data.zip') \n",
    "test_df = pd.read_csv(testzip.open('test_final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7622150c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ogfilename</th>\n",
       "      <th>label</th>\n",
       "      <th>filename</th>\n",
       "      <th>type</th>\n",
       "      <th>lung1</th>\n",
       "      <th>lung2</th>\n",
       "      <th>view</th>\n",
       "      <th>Covid</th>\n",
       "      <th>width</th>\n",
       "      <th>height</th>\n",
       "      <th>json_filename</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_258...</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_285...</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_329...</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_467...</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_704...</td>\n",
       "      <td>C</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1134</th>\n",
       "      <td>person1377_virus_2369.jpeg</td>\n",
       "      <td>D</td>\n",
       "      <td>00001225.jpeg</td>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>{'path': [{'x': 617, 'y': 86}, {'x': 605, 'y':...</td>\n",
       "      <td>{'path': [{'x': 791, 'y': 54}, {'x': 789, 'y':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1584.0</td>\n",
       "      <td>720.0</td>\n",
       "      <td>person1377_virus_2369.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1135</th>\n",
       "      <td>person1488_virus_2592.jpeg</td>\n",
       "      <td>D</td>\n",
       "      <td>00001170.jpeg</td>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>{'path': [{'x': 568, 'y': 138}, {'x': 563, 'y'...</td>\n",
       "      <td>{'path': [{'x': 789, 'y': 133}, {'x': 789, 'y'...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1504.0</td>\n",
       "      <td>1096.0</td>\n",
       "      <td>person1488_virus_2592.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1136</th>\n",
       "      <td>person500_virus_1009.jpeg</td>\n",
       "      <td>D</td>\n",
       "      <td>00000745.jpeg</td>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>{'path': [{'x': 598.0, 'y': 81}, {'x': 596.0, ...</td>\n",
       "      <td>{'path': [{'x': 399, 'y': 90}, {'x': 398, 'y':...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>968.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>person500_virus_1009.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1137</th>\n",
       "      <td>person1270_virus_2163.jpeg</td>\n",
       "      <td>D</td>\n",
       "      <td>00001275.jpeg</td>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>{'path': [{'x': 533.0, 'y': 76}, {'x': 530, 'y...</td>\n",
       "      <td>{'path': [{'x': 778, 'y': 113.0}, {'x': 778, '...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1280.0</td>\n",
       "      <td>920.0</td>\n",
       "      <td>person1270_virus_2163.json</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1138</th>\n",
       "      <td>person1253_virus_2129.jpeg</td>\n",
       "      <td>D</td>\n",
       "      <td>00001473.jpeg</td>\n",
       "      <td>Viral Pneumonia</td>\n",
       "      <td>{'path': [{'x': 432.0, 'y': 108.0}, {'x': 430,...</td>\n",
       "      <td>{'path': [{'x': 605, 'y': 55.0}, {'x': 600, 'y...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>False</td>\n",
       "      <td>1064.0</td>\n",
       "      <td>632.0</td>\n",
       "      <td>person1253_virus_2129.json</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1139 rows Ã— 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             ogfilename label       filename  \\\n",
       "0     aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_258...     C            NaN   \n",
       "1     aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_285...     C            NaN   \n",
       "2     aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_329...     C            NaN   \n",
       "3     aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_467...     C            NaN   \n",
       "4     aug_1-s2.0-S0196070920301691-gr3_lrg.jpg_0_704...     C            NaN   \n",
       "...                                                 ...   ...            ...   \n",
       "1134                         person1377_virus_2369.jpeg     D  00001225.jpeg   \n",
       "1135                         person1488_virus_2592.jpeg     D  00001170.jpeg   \n",
       "1136                          person500_virus_1009.jpeg     D  00000745.jpeg   \n",
       "1137                         person1270_virus_2163.jpeg     D  00001275.jpeg   \n",
       "1138                         person1253_virus_2129.jpeg     D  00001473.jpeg   \n",
       "\n",
       "                 type                                              lung1  \\\n",
       "0                 NaN                                                NaN   \n",
       "1                 NaN                                                NaN   \n",
       "2                 NaN                                                NaN   \n",
       "3                 NaN                                                NaN   \n",
       "4                 NaN                                                NaN   \n",
       "...               ...                                                ...   \n",
       "1134  Viral Pneumonia  {'path': [{'x': 617, 'y': 86}, {'x': 605, 'y':...   \n",
       "1135  Viral Pneumonia  {'path': [{'x': 568, 'y': 138}, {'x': 563, 'y'...   \n",
       "1136  Viral Pneumonia  {'path': [{'x': 598.0, 'y': 81}, {'x': 596.0, ...   \n",
       "1137  Viral Pneumonia  {'path': [{'x': 533.0, 'y': 76}, {'x': 530, 'y...   \n",
       "1138  Viral Pneumonia  {'path': [{'x': 432.0, 'y': 108.0}, {'x': 430,...   \n",
       "\n",
       "                                                  lung2 view  Covid   width  \\\n",
       "0                                                   NaN  NaN    NaN     NaN   \n",
       "1                                                   NaN  NaN    NaN     NaN   \n",
       "2                                                   NaN  NaN    NaN     NaN   \n",
       "3                                                   NaN  NaN    NaN     NaN   \n",
       "4                                                   NaN  NaN    NaN     NaN   \n",
       "...                                                 ...  ...    ...     ...   \n",
       "1134  {'path': [{'x': 791, 'y': 54}, {'x': 789, 'y':...  NaN  False  1584.0   \n",
       "1135  {'path': [{'x': 789, 'y': 133}, {'x': 789, 'y'...  NaN  False  1504.0   \n",
       "1136  {'path': [{'x': 399, 'y': 90}, {'x': 398, 'y':...  NaN  False   968.0   \n",
       "1137  {'path': [{'x': 778, 'y': 113.0}, {'x': 778, '...  NaN  False  1280.0   \n",
       "1138  {'path': [{'x': 605, 'y': 55.0}, {'x': 600, 'y...  NaN  False  1064.0   \n",
       "\n",
       "      height               json_filename  \n",
       "0        NaN                         NaN  \n",
       "1        NaN                         NaN  \n",
       "2        NaN                         NaN  \n",
       "3        NaN                         NaN  \n",
       "4        NaN                         NaN  \n",
       "...      ...                         ...  \n",
       "1134   720.0  person1377_virus_2369.json  \n",
       "1135  1096.0  person1488_virus_2592.json  \n",
       "1136   632.0   person500_virus_1009.json  \n",
       "1137   920.0  person1270_virus_2163.json  \n",
       "1138   632.0  person1253_virus_2129.json  \n",
       "\n",
       "[1139 rows x 11 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9275b637",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1fdf0a0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(df, imgloc):\n",
    "    data = []\n",
    "    for i in df['ogfilename']:\n",
    "        img = load_img(imgloc + \"ALL/\"+i)\n",
    "        x = img_to_array(img)\n",
    "        x = x/255\n",
    "        if img.size > (224,224) or img.size < (244,244):\n",
    "            x = tf.image.resize_with_pad(x, 224, 224, method=\"nearest\")\n",
    "            data.append(x)\n",
    "        else:\n",
    "            data.append(x)\n",
    "    return np.asarray(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "c530ad00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 9119 validated image filenames belonging to 4 classes.\n",
      "Found 1139 validated image filenames belonging to 4 classes.\n",
      "Found 635 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "seed = 4\n",
    "datagenerator =  ImageDataGenerator(rescale= 1/255)\n",
    "\n",
    "# Make train rescled\n",
    "train_data = datagenerator.flow_from_dataframe(\n",
    "        dataframe = train_df,\n",
    "        directory = all_img_loc,\n",
    "        x_col = \"ogfilename\",\n",
    "        y_col = \"label\",\n",
    "        class_mode = \"categorical\",\n",
    "        batch_size = 40,\n",
    "        seed = seed,\n",
    "        shuffle = True,\n",
    "        target_size = (224,224), # changed values for vgg16\n",
    "        keep_aspect_ratio = True,\n",
    "        validate_filenames= True)\n",
    "\n",
    "# Make val data\n",
    "val_data = datagenerator.flow_from_dataframe(\n",
    "        dataframe = val_df,\n",
    "        directory = all_img_loc,\n",
    "        x_col = \"ogfilename\",\n",
    "        y_col = \"label\",\n",
    "        class_mode = \"categorical\",\n",
    "        batch_size = 40,\n",
    "        seed = seed,\n",
    "        shuffle = True,\n",
    "        target_size = (224,224), # changed values for vgg16\n",
    "        keep_aspect_ratio = True,\n",
    "        validate_filenames= True)\n",
    "\n",
    "# Make test data\n",
    "test_data = datagenerator.flow_from_dataframe(\n",
    "        dataframe = test_df,\n",
    "        directory = all_img_loc,\n",
    "        x_col = \"ogfilename\",\n",
    "        y_col = None,\n",
    "        class_mode = None,\n",
    "        batch_size = 1,\n",
    "        seed = seed,\n",
    "        shuffle = False,\n",
    "        target_size = (224,224), # changed values for vgg16\n",
    "        keep_aspect_ratio = True,\n",
    "        validate_filenames= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "862fa5cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "716fdfe8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data = get_data(train_df, augmented_image_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a40447d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_data = get_data(val_df, augmented_image_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f41e7a46",
   "metadata": {},
   "outputs": [],
   "source": [
    "#test_data = get_data(test_df, augmented_image_loc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "92e6a939",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_cats = train_df.label\n",
    "#val_cats = val_df.label\n",
    "#test_cats = test_df.label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ad946d4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "#train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "645228e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9119"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#len(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e13e7ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = {'lr': (0.001, 0.01, 0.1, 0.2),\n",
    "     'batch_size': (10, 20, 30),\n",
    "     'epochs': [50],\n",
    "     'dropout': (0, 0.2, 0.5),\n",
    "     'optimizer': [Adam, RMSprop, SGD]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "728728fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(train_data, val_data, params):\n",
    "    vgg =  VGG16(weights=\"imagenet\", include_top=False, input_shape = (224,224,3))\n",
    "    model = Sequential()\n",
    "    model.add(vgg)\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Flatten())\n",
    "    model.add(Dropout(params['dropout']))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    model.layers[0].trainable = False\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "                  # here we add a regulizer normalization function from Talos\n",
    "                  optimizer=params['optimizer'](lr=0.001),\n",
    "                  metrics=['accuracy'])\n",
    "    history = model.fit(train_data, \n",
    "                    validation_data= val_data,\n",
    "                    batch_size=params['batch_size'],\n",
    "                    epochs=params['epochs'],\n",
    "                    verbose=0)\n",
    "    return history, model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62bea698",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c70969b6",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn [33], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m t \u001b[38;5;241m=\u001b[39m \u001b[43mtalos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mScan\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      2\u001b[0m \u001b[43m            \u001b[49m\u001b[43my\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mval_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      3\u001b[0m \u001b[43m            \u001b[49m\u001b[43mparams\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mp\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      4\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mget_model\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m      5\u001b[0m \u001b[43m            \u001b[49m\u001b[43mexperiment_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mimagenet\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\talos\\scan\\Scan.py:196\u001b[0m, in \u001b[0;36mScan.__init__\u001b[1;34m(self, x, y, params, model, experiment_name, x_val, y_val, val_split, random_method, seed, performance_target, fraction_limit, round_limit, time_limit, boolean_limit, reduction_method, reduction_interval, reduction_window, reduction_threshold, reduction_metric, minimize_loss, disable_progress_bar, print_params, clear_session, save_weights)\u001b[0m\n\u001b[0;32m    192\u001b[0m \u001b[38;5;66;03m# input parameters section ends\u001b[39;00m\n\u001b[0;32m    193\u001b[0m \n\u001b[0;32m    194\u001b[0m \u001b[38;5;66;03m# start runtime\u001b[39;00m\n\u001b[0;32m    195\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_run\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan_run\n\u001b[1;32m--> 196\u001b[0m \u001b[43mscan_run\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\talos\\scan\\scan_run.py:9\u001b[0m, in \u001b[0;36mscan_run\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mscan_prepare\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m scan_prepare\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mscan_prepare\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     11\u001b[0m \u001b[38;5;66;03m# initiate the progress bar\u001b[39;00m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpbar \u001b[38;5;241m=\u001b[39m tqdm(total\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mparam_object\u001b[38;5;241m.\u001b[39mparam_index),\n\u001b[0;32m     13\u001b[0m                  disable\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdisable_progress_bar)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\talos\\scan\\scan_prepare.py:47\u001b[0m, in \u001b[0;36mscan_prepare\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     45\u001b[0m \u001b[38;5;66;03m# handle validation split\u001b[39;00m\n\u001b[0;32m     46\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mvalidation_split\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m validation_split\n\u001b[1;32m---> 47\u001b[0m \u001b[38;5;28mself\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mvalidation_split\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;66;03m# set data and len\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_len \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\talos\\utils\\validation_split.py:14\u001b[0m, in \u001b[0;36mvalidation_split\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my_train \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my\n\u001b[0;32m     10\u001b[0m     \u001b[38;5;66;03m# self.x/y_val are already set\u001b[39;00m\n\u001b[0;32m     11\u001b[0m \n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;66;03m# shuffle the data before splitting\u001b[39;00m\n\u001b[1;32m---> 14\u001b[0m     \u001b[43mrandom_shuffle\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m     \u001b[38;5;66;03m# deduce the midway point for input data\u001b[39;00m\n\u001b[0;32m     17\u001b[0m     limit \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx) \u001b[38;5;241m*\u001b[39m (\u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mval_split))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\talos\\utils\\validation_split.py:62\u001b[0m, in \u001b[0;36mrandom_shuffle\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m     60\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     61\u001b[0m     ix \u001b[38;5;241m=\u001b[39m randomize(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx)\n\u001b[1;32m---> 62\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mx \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mx\u001b[49m\u001b[43m[\u001b[49m\u001b[43mix\u001b[49m\u001b[43m]\u001b[49m\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39my[ix]\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras_preprocessing\\image\\iterator.py:53\u001b[0m, in \u001b[0;36mIterator.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     52\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__getitem__\u001b[39m(\u001b[38;5;28mself\u001b[39m, idx):\n\u001b[1;32m---> 53\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43midx\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m>\u001b[39;49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m:\n\u001b[0;32m     54\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAsked to retrieve element \u001b[39m\u001b[38;5;132;01m{idx}\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     55\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbut the Sequence \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     56\u001b[0m                          \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhas length \u001b[39m\u001b[38;5;132;01m{length}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(idx\u001b[38;5;241m=\u001b[39midx,\n\u001b[0;32m     57\u001b[0m                                                       length\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m)))\n\u001b[0;32m     58\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mseed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "\u001b[1;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "t = talos.Scan(x=train_data,\n",
    "            y=val_data,\n",
    "            params=p,\n",
    "            model=get_model,\n",
    "            experiment_name='imagenet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f254f478",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4efb2e2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c1d83fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5cc9451",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "53be512d",
   "metadata": {},
   "source": [
    "# NOT WORKING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43320e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_gridsearch = False\n",
    "\n",
    "if run_gridsearch:\n",
    "    #if verbose: print (time.strftime( \"%H:%M:%S \" + \"GridSearch started ... \" ) )\n",
    "    #optimizers = ['rmsprop', 'adam']\n",
    "    epochs = [50, 100, 200, 400]\n",
    "    batches = [5, 10, 20]\n",
    "    \n",
    "    model = KerasClassifier(build_fn=get_model(), verbose=0)\n",
    "    \n",
    "    param_grid = dict(epochs=epochs, batch_size=batches)\n",
    "    grid = GridSearchCV(estimator=model, param_grid=param_grid)\n",
    "    grid_result = grid.fit(train_data, train_cats)\n",
    "    \n",
    "    # summarize results\n",
    "    print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "    means = grid_result.cv_results_['mean_test_score']\n",
    "    stds = grid_result.cv_results_['std_test_score']\n",
    "    params = grid_result.cv_results_['params']\n",
    "    if verbose: \n",
    "        for mean, stdev, param in zip(means, stds, params):\n",
    "            print(\"%f (%f) with: %r\" % (mean, stdev, param))\n",
    "        elapsed_time = time.time() - start_time  \n",
    "        print (\"Time elapsed: \",timedelta(seconds=elapsed_time))\n",
    "        \n",
    "    best_epochs = grid_result.best_params_['epochs']\n",
    "    best_batch_size = grid_result.best_params_['batch_size']\n",
    "    best_init = grid_result.best_params_['init']\n",
    "    best_optimizer = grid_result.best_params_['optimizer']\n",
    "    \n",
    "else:\n",
    "    # pre-selected paramters\n",
    "    best_epochs = 200\n",
    "    best_batch_size = 5\n",
    "    best_init = 'glorot_uniform'\n",
    "    best_optimizer = 'rmsprop'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f499678d",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = KerasClassifier(build_fn=get_model(\"imagenet\", False, (224,224,3), False, 4), epochs=100, batch_size=10, verbose=0)\n",
    "\n",
    "#batch_size = [20,30,40]\n",
    "#epochs = [20,30,40,50,60]\n",
    "optimizers = [\"Adam\", \"RMSprop\"]\n",
    "learn_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n",
    "momentum = [0.0, 0.2, 0.4, 0.6, 0.8, 0.9]\n",
    "\n",
    "param_grid = dict(optimizer__optimizer = optimizers, \n",
    "                  optimizer__learning_rate=learn_rate, optimizer__momentum=momentum)\n",
    "\n",
    "grid = GridSearchCV(estimator=model, param_grid=param_grid, n_jobs=-1, cv=3)\n",
    "grid_result = grid.fit(train_data, train_cats)\n",
    "\n",
    "print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n",
    "means = grid_result.cv_results_['mean_test_score']\n",
    "stds = grid_result.cv_results_['std_test_score']\n",
    "params = grid_result.cv_results_['params']\n",
    "for mean, stdev, param in zip(means, stds, params):\n",
    "    print(\"%f (%f) with: %r\" % (mean, stdev, param))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
